<html><head><meta charset="utf-8" /><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" /><title>Fetch</title><meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="description" content="Simple &amp; Efficient data access for Scala and Scala.js" /><meta name="author" content="47 Degrees" /><meta name="og:image" content="/fetch/img/poster.png" /><meta name="og:title" content="Fetch" /><meta name="og:site_name" content="Fetch" /><meta name="og:url" content="http://47deg.github.io/fetch/" /><meta name="og:type" content="website" /><meta name="og:description" content="Simple &amp; Efficient data access for Scala and Scala.js" /><meta name="twitter:image" content="/fetch/img/poster.png" /><meta name="twitter:card" content="summary_large_image" /><meta name="twitter:site" content="" /><link rel="icon" type="image/png" href="/fetch/img/favicon.png" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" /><link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.5.0/css/font-awesome.min.css" /><link rel="stylesheet" href="/fetch/highlight/styles/tomorrow.css" /><link rel="stylesheet" href="/fetch/css/style.css" /><link rel="stylesheet" href="/fetch/css/palette.css" /></head><body class="docs"><div id="wrapper"><div id="sidebar-wrapper"><ul id="sidebar" class="sidebar-nav"><li class="sidebar-brand"><a href="/fetch/" class="brand"><div class="brand-wrapper" style="background:url('/fetch/img/sidebar_brand.png') no-repeat"><span>Fetch</span></div></a></li><li><a href="/fetch/docs.html" class=" active "></a></li><li><a href="/fetch/" class=" active "></a></li><li><a href="/fetch/css/palette.css" class=" active "></a></li><li><a href="/fetch/css/style.css" class=" active "></a></li></ul></div><div id="page-content-wrapper"><div class="nav"><div class="container-fluid"><div class="row"><div class="col-lg-12"><div class="action-menu pull-left clearfix"><a href="#menu-toggle" id="menu-toggle"><i class="fa fa-bars" aria-hidden="true"></i></a></div><ul class="pull-right"><li class="hidden-xs"><a href="https://github.com/47deg/fetch"><i class="fa fa-eye"></i><span>WATCH<span id="eyes" class="label label-default">--</span></span></a></li><li class="hidden-xs"><a href="https://github.com/47deg/fetch"><i class="fa fa-star-o"></i><span>STARS<span id="stars" class="label label-default">--</span></span></a></li><li><a href="#" onclick="shareSiteTwitter('Fetch Simple &amp; Efficient data access for Scala and Scala.js');"><i class="fa fa-twitter"></i></a></li><li><a href="#" onclick="shareSiteFacebook('Fetch Simple &amp; Efficient data access for Scala and Scala.js');"><i class="fa fa-facebook"></i></a></li><li><a href="#" onclick="shareSiteGoogle();"><i class="fa fa-google-plus"></i></a></li></ul></div></div></div></div><div id="content" data-github-owner="47deg" data-github-repo="fetch"><div class="content-wrapper"><section><h1 id="introduction">Introduction</h1>

<p>Fetch is a library that allows your data fetches to be written in a concise,
composable way while executing efficiently. You don’t need to use any explicit
concurrency construct but existing idioms: applicative for concurrency and
monad for sequencing.</p>

<p>Oftentimes, our applications read and manipulate data from a variety of
different sources such as databases, web services or file systems. These data
sources are subject to latency, and we’d prefer to query them efficiently.</p>

<p>If we are just reading data, we can make a series of optimizations such as:</p>

<ul>
  <li>batching requests to the same data source</li>
  <li>requesting independent data from different sources in parallel</li>
  <li>caching previously seen results</li>
</ul>

<p>However, if we mix these optimizations with the code that fetches the data
we may end up trading clarity for performance. Furthermore, we are
mixing low-level (optimization) and high-level (business logic with the data
we read) concerns.</p>

<h1 id="installation">Installation</h1>

<p>To begin, add the following dependency to your SBT build file:</p>

<pre><code class="language-scala">"com.fortysevendeg" %% "fetch" % "0.4.1-SNAPSHOT"
</code></pre>

<p>Or, if using Scala.js:</p>

<pre><code class="language-scala">"com.fortysevendeg" %%% "fetch" % "0.4.1-SNAPSHOT"
</code></pre>

<p>Now you’ll have Fetch available in both Scala and Scala.js.</p>

<h2 id="alternatives">Alternatives</h2>

<p>There are other libraries in Scala that implement the same optimizations as Fetch does and have different design decisions. If Fetch is not suitable for you these alternatives may be a better fit:</p>

<ul>
  <li><a href="http://getclump.io/">Clump</a> it’s been around for a long time and is used in production systems at SoundCloud and LinkedIn. You can use it with Scala’s or Twitter’s Futures.</li>
  <li><a href="https://github.com/resolvable/resolvable">Resolvable</a> can be used with Scala Futures.</li>
</ul>

<p>If something is missing in Fetch that stops you from using it we’d appreciate if you <a href="https://github.com/47deg/fetch/issues">open an issue in our repository</a>.</p>

<h1 id="usage">Usage</h1>

<p>In order to tell Fetch how to retrieve data, we must implement the <code>DataSource</code> typeclass.</p>

<pre><code class="language-scala">import cats.data.NonEmptyList

trait DataSource[Identity, Result]{
  def name: String
  def fetchOne(id: Identity): Query[Option[Result]]
  def fetchMany(ids: NonEmptyList[Identity]): Query[Map[Identity, Result]]
}
</code></pre>

<p>It takes two type parameters:</p>

<ul>
  <li><code>Identity</code>: the identity we want to fetch (a <code>UserId</code> if we were fetching users)</li>
  <li><code>Result</code>: the type of the data we retrieve (a <code>User</code> if we were fetching users)</li>
</ul>

<p>There are two methods: <code>fetchOne</code> and <code>fetchMany</code>. <code>fetchOne</code> receives one identity and must return
a <code>Query</code> containing
an optional result. Returning an <code>Option</code> Fetch can detect whether an identity couldn’t be fetched or no longer exists.</p>

<p><code>fetchMany</code> method takes a non-empty list of identities and must return a <code>Query</code> containing
a map from identities to results. Accepting a list of identities gives Fetch the ability to batch requests to
the same data source, and returning a mapping from identities to results, Fetch can detect whenever an identity
couldn’t be fetched or no longer exists.</p>

<p>Returning <code>Query</code> makes it possible to run a fetch independently of the target monad.</p>

<h2 id="writing-your-first-data-source">Writing your first data source</h2>

<p>Now that we know about the <code>DataSource</code> typeclass, let’s write our first data source! We’ll start by implementing a data
source for fetching users given their id. The first thing we’ll do is define the types for user ids and users.</p>

<pre><code class="language-scala">type UserId = Int
case class User(id: UserId, username: String)
</code></pre>

<p>We’ll simulate unpredictable latency with this function.</p>

<pre><code class="language-scala">def latency[A](result: A, msg: String) = {
  val id = Thread.currentThread.getId
  println(s"~~&gt; [$id] $msg")
  Thread.sleep(100)
  println(s"&lt;~~ [$id] $msg")
  result
}
</code></pre>

<p>And now we’re ready to write our user data source; we’ll emulate a database with an in-memory map.</p>

<pre><code class="language-scala">import cats.data.NonEmptyList
import cats.instances.list._

import fetch._

val userDatabase: Map[UserId, User] = Map(
  1 -&gt; User(1, "@one"),
  2 -&gt; User(2, "@two"),
  3 -&gt; User(3, "@three"),
  4 -&gt; User(4, "@four")
)

implicit object UserSource extends DataSource[UserId, User]{
  override def name = "User"

  override def fetchOne(id: UserId): Query[Option[User]] = {
    Query.sync({
	  latency(userDatabase.get(id), s"One User $id")
    })
  }
  override def fetchMany(ids: NonEmptyList[UserId]): Query[Map[UserId, User]] = {
    Query.sync({
	  latency(userDatabase.filterKeys(ids.toList.contains), s"Many Users $ids")
    })
  }
}
</code></pre>

<p>Now that we have a data source we can write a function for fetching users
given an id, we just have to pass a <code>UserId</code> as an argument to <code>Fetch</code>.</p>

<pre><code class="language-scala">def getUser(id: UserId): Fetch[User] = Fetch(id) // or, more explicitly: Fetch(id)(UserSource)
</code></pre>

<h3 id="data-sources-that-dont-support-batching">Data sources that don’t support batching</h3>

<p>If your data source doesn’t support batching, you can use the <code>DataSource#batchingNotSupported</code> method as the implementation
of <code>fetchMany</code>. Note that it will use the <code>fetchOne</code> implementation for requesting identities one at a time.</p>

<pre><code class="language-scala">implicit object UnbatchedSource extends DataSource[Int, Int]{
  override def name = "Unbatched"
  
  override def fetchOne(id: Int): Query[Option[Int]] = {
    Query.sync(Option(id))
  }
  override def fetchMany(ids: NonEmptyList[Int]): Query[Map[Int, Int]] = {
    batchingNotSupported(ids)
  }
}
</code></pre>

<h2 id="creating-and-running-a-fetch">Creating and running a fetch</h2>

<p>We are now ready to create and run fetches. Note the distinction between Fetch creation and execution.
When we are creating and combining <code>Fetch</code> values, we are just constructing a recipe of our data
dependencies.</p>

<pre><code class="language-scala">val fetchUser: Fetch[User] = getUser(1)
</code></pre>

<p>A <code>Fetch</code> is just a value, and in order to be able to get its value we need to run it to a monad first. The
target monad <code>M[_]</code> must be able to lift a <code>Query[A]</code> to <code>M[A]</code>, evaluating the query in the monad’s context.</p>

<p>We’ll run <code>fetchUser</code> using <code>Id</code> as our target monad, so let’s do some imports first. Note that interpreting
a fetch to a non-concurrency monad like <code>Id</code> or <code>Eval</code> is only recommended for trying things out in a Scala
console, that’s why for using them you need to import <code>fetch.unsafe.implicits</code>.</p>

<pre><code class="language-scala">import cats.Id
import fetch.unsafe.implicits._
import fetch.syntax._
</code></pre>

<p>Note that running a fetch to non-concurrency monads like <code>Id</code> or <code>Eval</code> is not supported in Scala.js.
In real-life scenarios you’ll want to run your fetches to <code>Future</code> or a <code>Task</code> type provided by a library like
<a href="https://monix.io/">Monix</a> or <a href="https://github.com/functional-streams-for-scala/fs2">fs2</a>, both of which are supported
in Fetch.</p>

<p>We can now run the fetch and see its result:</p>

<pre><code class="language-scala">fetchUser.runA[Id]
// ~~&gt; [44] One User 1
// &lt;~~ [44] One User 1
// res3: cats.Id[User] = User(1,@one)
</code></pre>

<h3 id="sequencing">Sequencing</h3>

<p>When we have two fetches that depend on each other, we can use <code>flatMap</code> to combine them. The most straightforward way is to use a for comprehension:</p>

<pre><code class="language-scala">val fetchTwoUsers: Fetch[(User, User)] = for {
  aUser &lt;- getUser(1)
  anotherUser &lt;- getUser(aUser.id + 1)
} yield (aUser, anotherUser)
</code></pre>

<p>When composing fetches with <code>flatMap</code> we are telling Fetch that the second one depends on the previous one, so it isn’t able to make any optimizations. When running the above fetch, we will query the user data source in two rounds: one for the user with id 1 and another for the user with id 2.</p>

<pre><code class="language-scala">fetchTwoUsers.runA[Id]
// ~~&gt; [44] One User 1
// &lt;~~ [44] One User 1
// ~~&gt; [44] One User 2
// &lt;~~ [44] One User 2
// res4: cats.Id[(User, User)] = (User(1,@one),User(2,@two))
</code></pre>

<h3 id="batching">Batching</h3>

<p>If we combine two independent requests to the same data source, Fetch will
automatically batch them together into a single request. Applicative operations like the product of two fetches
help us tell the library that those fetches are independent, and thus can be batched if they use the same data source:</p>

<pre><code class="language-scala">import cats.syntax.cartesian._

val fetchProduct: Fetch[(User, User)] = getUser(1).product(getUser(2))
</code></pre>

<p>Note how both ids (1 and 2) are requested in a single query to the data source when executing the fetch.</p>

<pre><code class="language-scala">fetchProduct.runA[Id]
// ~~&gt; [44] Many Users NonEmptyList(1, 2)
// &lt;~~ [44] Many Users NonEmptyList(1, 2)
// res6: cats.Id[(User, User)] = (User(1,@one),User(2,@two))
</code></pre>

<h3 id="deduplication">Deduplication</h3>

<p>If two independent requests ask for the same identity, Fetch will detect it and deduplicate the id.</p>

<pre><code class="language-scala">val fetchDuped: Fetch[(User, User)] = getUser(1).product(getUser(1))
</code></pre>

<p>Note that when running the fetch, the identity 1 is only requested once even when it is needed by both fetches.</p>

<pre><code class="language-scala">fetchDuped.runA[Id]
// ~~&gt; [44] One User 1
// &lt;~~ [44] One User 1
// res7: cats.Id[(User, User)] = (User(1,@one),User(1,@one))
</code></pre>

<h3 id="caching">Caching</h3>

<p>During the execution of a fetch, previously requested results are implicitly cached. This allows us to write
fetches in a very modular way, asking for all the data they need as if it
was in memory; furthermore, it also avoids re-fetching an identity that may have changed
during the course of a fetch execution, which can lead to inconsistencies in the data.</p>

<pre><code class="language-scala">val fetchCached: Fetch[(User, User)] = for {
  aUser &lt;- getUser(1)
  anotherUser &lt;- getUser(1)
} yield (aUser, anotherUser)
</code></pre>

<p>The above fetch asks for the same identity multiple times. Let’s see what happens when executing it.</p>

<pre><code class="language-scala">fetchCached.runA[Id]
// ~~&gt; [44] One User 1
// &lt;~~ [44] One User 1
// res8: cats.Id[(User, User)] = (User(1,@one),User(1,@one))
</code></pre>

<p>As you can see, the <code>User</code> with id 1 was fetched only once in a single round-trip. The next
time it was needed we used the cached versions, thus avoiding another request to the user data
source.</p>

<h2 id="queries">Queries</h2>

<p>Queries are a way of separating the computation required to read a piece of data from the context in
which is run. Let’s look at the various ways we have of constructing queries.</p>

<h3 id="synchronous">Synchronous</h3>

<p>A query can be synchronous, and we may want to evaluate it when <code>fetchOne</code> and <code>fetchMany</code>
are called. We can do so with <code>Query#sync</code>:</p>

<pre><code class="language-scala">Query.sync(42)
// res9: fetch.Query[Int] = Sync(cats.Later@4b39080f)
</code></pre>

<p>You can also construct lazy queries that can evaluate synchronously passing a thunk to <code>Query#sync</code>:</p>

<pre><code class="language-scala">Query.sync({ println("Computing 42"); 42 })
// res10: fetch.Query[Int] = Sync(cats.Later@1f83ca08)
</code></pre>

<p>Synchronous queries simply wrap a Cats’ <code>Eval</code> instance, which captures the notion of a lazy synchronous
computation. You can lift an <code>Eval[A]</code> into a <code>Query[A]</code> too:</p>

<pre><code class="language-scala">import cats.Eval
// import cats.Eval

Query.eval(Eval.always({ println("Computing 42"); 42 }))
// res11: fetch.Query[Int] = Sync(cats.Always@f0999d4)
</code></pre>

<h3 id="asynchronous">Asynchronous</h3>

<p>Asynchronous queries are constructed passing a function that accepts a callback (<code>A =&gt; Unit</code>) and an errback
(<code>Throwable =&gt; Unit</code>) and performs the asynchronous computation. Note that you must ensure that either the
callback or the errback are called.</p>

<pre><code class="language-scala">Query.async((ok: (Int =&gt; Unit), fail) =&gt; {
  Thread.sleep(100)
  ok(42)
})
// res12: fetch.Query[Int] = Async($$Lambda$1778/1629532722@494d5a50,Duration.Inf)
</code></pre>

<h2 id="combining-data-from-multiple-sources">Combining data from multiple sources</h2>

<p>Now that we know about some of the optimizations that Fetch can perform to read data efficiently,
let’s look at how we can combine more than one data source.</p>

<p>Imagine that we are rendering a blog and have the following types for posts:</p>

<pre><code class="language-scala">type PostId = Int
case class Post(id: PostId, author: UserId, content: String)
</code></pre>

<p>As you can see, every <code>Post</code> has an author, but it refers to the author by its id. We’ll implement a data source for retrieving a post given a post id.</p>

<pre><code class="language-scala">val postDatabase: Map[PostId, Post] = Map(
  1 -&gt; Post(1, 2, "An article"),
  2 -&gt; Post(2, 3, "Another article"),
  3 -&gt; Post(3, 4, "Yet another article")
)

implicit object PostSource extends DataSource[PostId, Post]{
  override def name = "Post"

  override def fetchOne(id: PostId): Query[Option[Post]] = {
    Query.sync({
	  latency(postDatabase.get(id), s"One Post $id")
    })
  }
  override def fetchMany(ids: NonEmptyList[PostId]): Query[Map[PostId, Post]] = {
    Query.sync({
	  latency(postDatabase.filterKeys(ids.toList.contains), s"Many Posts $ids")
    })
  }
}

def getPost(id: PostId): Fetch[Post] = Fetch(id)
</code></pre>

<p>We can also implement a function for fetching a post’s author given a post:</p>

<pre><code class="language-scala">def getAuthor(p: Post): Fetch[User] = Fetch(p.author)
</code></pre>

<p>Apart from posts, we are going to add another data source: one for post topics.</p>

<pre><code class="language-scala">type PostTopic = String
</code></pre>

<p>We’ll implement a data source for retrieving a post topic given a post id.</p>

<pre><code class="language-scala">implicit object PostTopicSource extends DataSource[Post, PostTopic]{
  override def name = "Post topic"

  override def fetchOne(id: Post): Query[Option[PostTopic]] = {
    Query.sync({
      val topic = if (id.id % 2 == 0) "monad" else "applicative"
      latency(Option(topic), s"One Post Topic $id")
    })
  }
  override def fetchMany(ids: NonEmptyList[Post]): Query[Map[Post, PostTopic]] = {
    Query.sync({
	  val result = ids.toList.map(id =&gt; (id, if (id.id % 2 == 0) "monad" else "applicative")).toMap
      latency(result, s"Many Post Topics $ids")
    })
  }
}

def getPostTopic(post: Post): Fetch[PostTopic] = Fetch(post)
</code></pre>

<p>Now that we have multiple sources let’s mix them in the same fetch.</p>

<pre><code class="language-scala">val fetchMulti: Fetch[(Post, PostTopic)] = for {
  post &lt;- getPost(1)
  topic &lt;- getPostTopic(post)
} yield (post, topic)
</code></pre>

<p>We can now run the previous fetch, querying the posts data source first and the user data source afterwards.</p>

<pre><code class="language-scala">fetchMulti.runA[Id]
// ~~&gt; [44] One Post 1
// &lt;~~ [44] One Post 1
// ~~&gt; [44] One Post Topic Post(1,2,An article)
// &lt;~~ [44] One Post Topic Post(1,2,An article)
// res16: cats.Id[(Post, PostTopic)] = (Post(1,2,An article),applicative)
</code></pre>

<p>In the previous example, we fetched a post given its id and then fetched its topic. This
data could come from entirely different places, but Fetch makes working with heterogeneous sources
of data very easy.</p>

<h3 id="concurrency">Concurrency</h3>

<p>Combining multiple independent requests to the same data source can have two outcomes:</p>

<ul>
  <li>if the data sources are the same, the request is batched</li>
  <li>otherwise, both data sources are queried at the same time</li>
</ul>

<p>In the following example we are fetching from different data sources so both requests will be
evaluated together.</p>

<pre><code class="language-scala">val fetchConcurrent: Fetch[(Post, User)] = getPost(1).product(getUser(2))
</code></pre>

<p>The above example combines data from two different sources, and the library knows they are independent.</p>

<pre><code class="language-scala">fetchConcurrent.runA[Id]
// ~~&gt; [44] One Post 1
// &lt;~~ [44] One Post 1
// ~~&gt; [44] One User 2
// &lt;~~ [44] One User 2
// res17: cats.Id[(Post, User)] = (Post(1,2,An article),User(2,@two))
</code></pre>

<p>Since we are running the fetch to <code>Id</code>, we couldn’t exploit parallelism for reading from both sources
at the same time. Let’s do some imports in order to be able to run fetches to a <code>Future</code>.</p>

<pre><code class="language-scala">import scala.concurrent._
import ExecutionContext.Implicits.global
import scala.concurrent.duration._
</code></pre>

<p>Let’s see what happens when running the same fetch to a <code>Future</code>, note that you cannot block for a
future’s result in Scala.js.</p>

<pre><code class="language-scala">import fetch.implicits._
// import fetch.implicits._

Await.result(fetchConcurrent.runA[Future], Duration.Inf)
// ~~&gt; [45] One Post 1
// ~~&gt; [47] One User 2
// &lt;~~ [45] One Post 1
// &lt;~~ [47] One User 2
// res18: (Post, User) = (Post(1,2,An article),User(2,@two))
</code></pre>

<p>As you can see, each independent request ran in its own logical thread.</p>

<h2 id="combinators">Combinators</h2>

<p>Besides <code>flatMap</code> for sequencing fetches and <code>product</code> for running them concurrently, Fetch provides a number of
other combinators.</p>

<h3 id="sequence">Sequence</h3>

<p>Whenever we have a list of fetches of the same type and want to run them concurrently, we can use the <code>sequence</code>
combinator. It takes a <code>List[Fetch[A]]</code> and gives you back a <code>Fetch[List[A]]</code>, batching the fetches to the same
data source and running fetches to different sources in parallel. Note that the <code>sequence</code> combinator is more general and works not only on lists but on any type that has a <a href="http://typelevel.org/cats/tut/traverse.html">Traverse</a> instance.</p>

<pre><code class="language-scala">import cats.instances.list._
import cats.syntax.traverse._

val fetchSequence: Fetch[List[User]] = List(getUser(1), getUser(2), getUser(3)).sequence
</code></pre>

<p>Since <code>sequence</code> uses applicative operations internally, the library is able to perform optimizations across all the sequenced fetches.</p>

<pre><code class="language-scala">fetchSequence.runA[Id]
// ~~&gt; [44] Many Users NonEmptyList(1, 2, 3)
// &lt;~~ [44] Many Users NonEmptyList(1, 2, 3)
// res20: cats.Id[List[User]] = List(User(1,@one), User(2,@two), User(3,@three))
</code></pre>

<p>As you can see, requests to the user data source were batched, thus fetching all the data in one round.</p>

<h3 id="traverse">Traverse</h3>

<p>Another interesting combinator is <code>traverse</code>, which is the composition of <code>map</code> and <code>sequence</code>.</p>

<pre><code class="language-scala">val fetchTraverse: Fetch[List[User]] = List(1, 2, 3).traverse(getUser)
</code></pre>

<p>As you may have guessed, all the optimizations made by <code>sequence</code> still apply when using <code>traverse</code>.</p>

<pre><code class="language-scala">fetchTraverse.runA[Id]
// ~~&gt; [44] Many Users NonEmptyList(1, 2, 3)
// &lt;~~ [44] Many Users NonEmptyList(1, 2, 3)
// res21: cats.Id[List[User]] = List(User(1,@one), User(2,@two), User(3,@three))
</code></pre>

<h1 id="caching-1">Caching</h1>

<p>As we have learned, Fetch caches intermediate results implicitly. You can
provide a prepopulated cache for running a fetch, replay a fetch with the cache of a previous
one, and even implement a custom cache.</p>

<h2 id="prepopulating-a-cache">Prepopulating a cache</h2>

<p>We’ll be using the default in-memory cache, prepopulated with some data. The cache key of an identity
is calculated with the <code>DataSource</code>’s <code>identity</code> method.</p>

<pre><code class="language-scala">val cache = InMemoryCache(UserSource.identity(1) -&gt; User(1, "@dialelo"))
// cache: fetch.InMemoryCache = InMemoryCache(Map((User,1) -&gt; User(1,@dialelo)))
</code></pre>

<p>We can pass a cache as the second argument when running a fetch with <code>Fetch.run</code>.</p>

<pre><code class="language-scala">Fetch.run[Id](fetchUser, cache)
// res22: cats.Id[User] = User(1,@dialelo)
</code></pre>

<p>And as the first when using fetch syntax:</p>

<pre><code class="language-scala">fetchUser.runA[Id](cache)
// res23: cats.Id[User] = User(1,@dialelo)
</code></pre>

<p>As you can see, when all the data is cached, no query to the data sources is executed since the results are available
in the cache.</p>

<pre><code class="language-scala">val fetchManyUsers: Fetch[List[User]] = List(1, 2, 3).traverse(getUser)
</code></pre>

<p>If only part of the data is cached, the cached data won’t be asked for:</p>

<pre><code class="language-scala">fetchManyUsers.runA[Id](cache)
// ~~&gt; [44] Many Users NonEmptyList(2, 3)
// &lt;~~ [44] Many Users NonEmptyList(2, 3)
// res24: cats.Id[List[User]] = List(User(1,@dialelo), User(2,@two), User(3,@three))
</code></pre>

<h2 id="replaying-a-fetch-without-querying-any-data-source">Replaying a fetch without querying any data source</h2>

<p>When running a fetch, we are generally interested in its final result. However, we also have access to the cache
and information about the executed rounds once we run a fetch. Fetch’s interpreter keeps its state in an environment
(implementing the <code>Env</code> trait), and we can get both the environment and result after running a fetch using <code>Fetch.runFetch</code>
instead of <code>Fetch.run</code> or <code>value.runF</code> via it’s implicit syntax.</p>

<p>Knowing this, we can replay a fetch reusing the cache of a previous one. The replayed fetch won’t have to call any of the
data sources.</p>

<pre><code class="language-scala">val env = fetchManyUsers.runE[Id]
// ~~&gt; [44] Many Users NonEmptyList(1, 2, 3)
// &lt;~~ [44] Many Users NonEmptyList(1, 2, 3)
// env: cats.Id[fetch.FetchEnv] = FetchEnv(InMemoryCache(Map((User,1) -&gt; User(1,@one), (User,2) -&gt; User(2,@two), (User,3) -&gt; User(3,@three))),Queue(Round(InMemoryCache(Map()),Concurrent(NonEmptyList(FetchMany(NonEmptyList(1, 2, 3),User))),NonEmptyList(Map(1 -&gt; User(1,@one), 2 -&gt; User(2,@two), 3 -&gt; User(3,@three))),24916292464188,24916394539441)))

fetchManyUsers.runA[Id](env.cache)
// res25: cats.Id[List[User]] = List(User(1,@one), User(2,@two), User(3,@three))
</code></pre>

<h2 id="implementing-a-custom-cache">Implementing a custom cache</h2>

<p>The default cache is implemented as an immutable in-memory map, but users are free to use their own caches when running a fetch. Your cache should implement the <code>DataSourceCache</code> trait, and after that you can pass it to Fetch’s <code>run</code> methods.</p>

<p>There is no need for the cache to be mutable since fetch executions run in an interpreter that uses the state monad. Note that the <code>update</code> method in the <code>DataSourceCache</code> trait yields a new, updated cache.</p>

<pre><code class="language-scala">trait DataSourceCache {
  def update[A](k: DataSourceIdentity, v: A): DataSourceCache
  def get[A](k: DataSourceIdentity): Option[A]
}
</code></pre>

<p>Let’s implement a cache that forgets everything we store in it.</p>

<pre><code class="language-scala">final case class ForgetfulCache() extends DataSourceCache {
  override def get[A](k: DataSourceIdentity): Option[A] = None
  override def update[A](k: DataSourceIdentity, v: A): ForgetfulCache = this
}
</code></pre>

<p>We can now use our implementation of the cache when running a fetch.</p>

<pre><code class="language-scala">val fetchSameTwice: Fetch[(User, User)] = for {
  one &lt;- getUser(1)
  another &lt;- getUser(1)
} yield (one, another)
// fetchSameTwice: fetch.Fetch[(User, User)] = Free(...)

fetchSameTwice.runA[Id](ForgetfulCache())
// ~~&gt; [44] One User 1
// &lt;~~ [44] One User 1
// ~~&gt; [44] One User 1
// &lt;~~ [44] One User 1
// res26: cats.Id[(User, User)] = (User(1,@one),User(1,@one))
</code></pre>

<h1 id="error-handling">Error handling</h1>

<p>Fetch is used for reading data from remote sources and the queries we perform can and will fail at some point. There are many things that can
go wrong:</p>
<ul>
  <li>an exception can be thrown by client code of certain data sources</li>
  <li>an identity may be missing</li>
  <li>the data source may be temporarily available</li>
</ul>

<p>Since the error cases are plenty and can’t be anticipated Fetch errors are represented by the <code>FetchException</code> trait, which extends <code>Throwable</code>.
Currently fetch defines <code>FetchException</code> cases for missing identities and arbitrary exceptions but you can extend <code>FetchException</code> with any error
you want.</p>

<h2 id="exceptions">Exceptions</h2>

<p>What happens if we run a fetch and fails with an exception? We’ll create a fetch that always fails to learn about it.</p>

<pre><code class="language-scala">val fetchException: Fetch[User] = (new Exception("Oh noes")).fetch
</code></pre>

<p>If we try to execute to <code>Id</code> the exception will be thrown wrapped in a <code>FetchException</code>.</p>

<pre><code class="language-scala">scala&gt; fetchException.runA[Id]
fetch.UnhandledException: java.lang.Exception: Oh noes
  at fetch.FetchInterpreters$$anon$1.$anonfun$apply$1(interpreters.scala:65)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.$anonfun$transformF$1(StateT.scala:81)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateTMonad.$anonfun$tailRecM$2(StateT.scala:236)
  at cats.package$$anon$1.tailRecM(package.scala:36)
  at fetch.unsafe.implicits$$anon$2.tailRecM(unsafeImplicits.scala:106)
  at cats.data.StateTMonad.$anonfun$tailRecM$1(StateT.scala:235)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.$anonfun$transformF$1(StateT.scala:81)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateTMonad.$anonfun$tailRecM$2(StateT.scala:236)
  at cats.package$$anon$1.tailRecM(package.scala:36)
  at fetch.unsafe.implicits$$anon$2.tailRecM(unsafeImplicits.scala:106)
  at cats.data.StateTMonad.$anonfun$tailRecM$1(StateT.scala:235)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.$anonfun$transformF$1(StateT.scala:81)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateTMonad.$anonfun$tailRecM$2(StateT.scala:236)
  at cats.package$$anon$1.tailRecM(package.scala:36)
  at fetch.unsafe.implicits$$anon$2.tailRecM(unsafeImplicits.scala:106)
  at cats.data.StateTMonad.$anonfun$tailRecM$1(StateT.scala:235)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.runA(StateT.scala:50)
  at fetch.package$Fetch$FetchRunnerA.apply(fetch.scala:242)
  at fetch.syntax$FetchSyntax$.runA$extension0(syntax.scala:48)
  ... 984 elided
Caused by: java.lang.Exception: Oh noes
  ... 952 more
</code></pre>

<p>Since <code>Id</code> runs the fetch eagerly, the only way to recover from errors when running it is surrounding it with a <code>try-catch</code> block. We’ll use Cats’ <code>Eval</code> type as the target
monad which, instead of evaluating the fetch eagerly, gives us an <code>Eval[A]</code> that we can run anytime with its <code>.value</code> method.</p>

<p>We can use the <code>FetchMonadError[Eval]#attempt</code> to convert a fetch result into a disjuntion and avoid throwing exceptions. Fetch provides an implicit instance of <code>FetchMonadError[Eval]</code> that we can import from <code>fetch.unsafe.implicits._</code> to have it available.</p>

<pre><code class="language-scala">import fetch.unsafe.implicits._
</code></pre>

<p>Now we can convert <code>Eval[User]</code> into <code>Eval[Either[FetchException, User]</code> and capture exceptions as values in the left of the disjunction.</p>

<pre><code class="language-scala">import cats.Eval
// import cats.Eval

val safeResult: Eval[Either[FetchException, User]] = FetchMonadError[Eval].attempt(fetchException.runA[Eval])
// safeResult: cats.Eval[Either[fetch.FetchException,User]] = cats.Later@31e0df14

safeResult.value
// res28: Either[fetch.FetchException,User] = Left(fetch.UnhandledException)
</code></pre>

<p>And more succintly with Cats’ applicative error syntax.</p>

<pre><code class="language-scala">import cats.syntax.applicativeError._
// import cats.syntax.applicativeError._

import fetch.unsafe.implicits._
// import fetch.unsafe.implicits._

fetchException.runA[Eval].attempt.value
// res29: Either[fetch.FetchException,User] = Left(fetch.UnhandledException)
</code></pre>

<h3 id="debugging-exceptions">Debugging exceptions</h3>

<p>Using fetch’s debugging facilities, we can visualize a failed fetch’s execution up until the point where it failed. Let’s create
a fetch that fails after a couple rounds to see it in action:</p>

<pre><code class="language-scala">val failingFetch: Fetch[String] = for {
  a &lt;- getUser(1)
  b &lt;- getUser(2)
  c &lt;- fetchException
} yield s"${a.username} loves ${b.username}"

val result: Eval[Either[FetchException, String]] = FetchMonadError[Eval].attempt(failingFetch.runA[Eval])
</code></pre>

<p>Now let’s use the <code>fetch.debug.describe</code> function for describing the error if we find one:</p>

<pre><code class="language-scala">import fetch.debug.describe
// import fetch.debug.describe

val value: Either[FetchException, String] = result.value
// ~~&gt; [44] One User 1
// &lt;~~ [44] One User 1
// ~~&gt; [44] One User 2
// &lt;~~ [44] One User 2
// value: Either[fetch.FetchException,String] = Left(fetch.UnhandledException)

println(value.fold(describe, identity _))
// [Error] Unhandled `java.lang.Exception`: 'Oh noes', fetch interrupted after 2 rounds
// Fetch execution took 0.203314 seconds
//   
//     [Fetch one] From `User` with id 1 took 0.000101 seconds
//     [Fetch one] From `User` with id 2 took 0.000101 seconds
</code></pre>

<p>As you can see in the output from <code>describe</code>, the fetch stopped due to a <code>java.lang.Exception</code> after succesfully executing two
rounds for getting users 1 and 2.</p>

<h2 id="missing-identities">Missing identities</h2>

<p>You’ve probably noticed that <code>DataSource.fetchOne</code> and <code>DataSource.fetchMany</code> return types help Fetch know if any requested
identity was not found. Whenever an identity cannot be found, the fetch execution will fail with an instance of <code>FetchException</code>.</p>

<p>The requests can be of different types, each of which is described below.</p>

<h3 id="one-request">One request</h3>

<p>When a single identity is being fetched the request will be a <code>FetchOne</code>; it contains the data source and the identity to fetch so you
should be able to easily diagnose the failure. For ilustrating this scenario we’ll ask for users that are not in the database.</p>

<pre><code class="language-scala">import cats.syntax.either._
import fetch.debug.describe

val missingUser = getUser(5)

val result: Eval[Either[FetchException, User]] = missingUser.runA[Eval].attempt
</code></pre>

<p>And now we can execute the fetch and describe its execution:</p>

<pre><code class="language-scala">val value: Either[FetchException, User] = result.value
// ~~&gt; [44] One User 5
// &lt;~~ [44] One User 5
// value: Either[fetch.FetchException,User] = Left(fetch.NotFound)

println(value.fold(describe, _.toString))
// [Error] Identity not found: 5 in `User`, fetch interrupted after 0 rounds
// 
</code></pre>

<p>As you can see in the output, the identity <code>5</code> for the user source was not found, thus the fetch failed without executing any rounds.
<code>NotFound</code> also allows you to access the fetch request that was in progress when the error happened and the environment of the fetch.</p>

<pre><code class="language-scala">value match {
  case Left(nf @ NotFound(_, _)) =&gt; {
    println("Request " + nf.request)
    println("Environment " + nf.env)
  }
  case _ =&gt; 
}
// Request FetchOne(5,User)
// Environment FetchEnv(InMemoryCache(Map()),Queue())
</code></pre>

<h3 id="multiple-requests">Multiple requests</h3>

<p>When multiple requests to the same data source are batched and/or multiple requests are performed at the same time, is possible that more than one identity was missing. There is another error case for such situations: <code>MissingIdentities</code>, which contains a mapping from data source names to the list of missing identities.</p>

<pre><code class="language-scala">import fetch.debug.describe
// import fetch.debug.describe

val missingUsers = List(3, 4, 5, 6).traverse(getUser)
// missingUsers: fetch.Fetch[List[User]] = Free(...)

val result: Eval[Either[FetchException, List[User]]] = missingUsers.runA[Eval].attempt
// result: cats.Eval[Either[fetch.FetchException,List[User]]] = cats.Later@7bf896f1
</code></pre>

<p>And now we can execute the fetch and describe its execution:</p>

<pre><code class="language-scala">val value: Either[FetchException, List[User]] = result.value
// ~~&gt; [44] Many Users NonEmptyList(3, 4, 5, 6)
// &lt;~~ [44] Many Users NonEmptyList(3, 4, 5, 6)
// value: Either[fetch.FetchException,List[User]] = Left(fetch.MissingIdentities)

println(value.fold(describe, _.toString))
// [Error] Missing identities, fetch interrupted after 0 rounds
// 
//   `User` missing identities List(5, 6)
// 
</code></pre>

<p>The <code>.missing</code> attribute will give us the mapping from data source name to missing identities, and <code>.env</code> will give us the environment so we can track the execution of the fetch.</p>

<pre><code class="language-scala">value match {
  case Left(mi @ MissingIdentities(_, _)) =&gt; {
    println("Missing identities " + mi.missing)
    println("Environment " + mi.env)
  }
  case _ =&gt;
}
// Missing identities Map(User -&gt; List(5, 6))
// Environment FetchEnv(InMemoryCache(Map()),Queue())
</code></pre>

<h2 id="your-own-errors">Your own errors</h2>

<h1 id="syntax">Syntax</h1>

<h2 id="implicit-syntax">Implicit syntax</h2>

<p>Fetch provides implicit syntax to lift any value to the context of a <code>Fetch</code> in addition to the most common used
combinators active within <code>Fetch</code> instances.</p>

<h3 id="pure">pure</h3>

<p>Plain values can be lifted to the Fetch monad with <code>value.fetch</code>:</p>

<pre><code class="language-scala">val fetchPure: Fetch[Int] = 42.fetch
</code></pre>

<p>Executing a pure fetch doesn’t query any data source, as expected.</p>

<pre><code class="language-scala">fetchPure.runA[Id]
// res38: cats.Id[Int] = 42
</code></pre>

<h3 id="error">error</h3>

<p>Errors can also be lifted to the Fetch monad via <code>exception.fetch</code>.</p>

<pre><code class="language-scala">val fetchFail: Fetch[Int] = new Exception("Something went terribly wrong").fetch
</code></pre>

<p>Note that interpreting an errorful fetch to <code>Id</code> will throw the exception.</p>

<pre><code class="language-scala">scala&gt; fetchFail.runA[Id]
fetch.UnhandledException: java.lang.Exception: Something went terribly wrong
  at fetch.FetchInterpreters$$anon$1.$anonfun$apply$1(interpreters.scala:65)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.$anonfun$transformF$1(StateT.scala:81)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateTMonad.$anonfun$tailRecM$2(StateT.scala:236)
  at cats.package$$anon$1.tailRecM(package.scala:36)
  at fetch.unsafe.implicits$$anon$2.tailRecM(unsafeImplicits.scala:106)
  at cats.data.StateTMonad.$anonfun$tailRecM$1(StateT.scala:235)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.$anonfun$transformF$1(StateT.scala:81)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateTMonad.$anonfun$tailRecM$2(StateT.scala:236)
  at cats.package$$anon$1.tailRecM(package.scala:36)
  at fetch.unsafe.implicits$$anon$2.tailRecM(unsafeImplicits.scala:106)
  at cats.data.StateTMonad.$anonfun$tailRecM$1(StateT.scala:235)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.$anonfun$transformF$1(StateT.scala:81)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateTMonad.$anonfun$tailRecM$2(StateT.scala:236)
  at cats.package$$anon$1.tailRecM(package.scala:36)
  at fetch.unsafe.implicits$$anon$2.tailRecM(unsafeImplicits.scala:106)
  at cats.data.StateTMonad.$anonfun$tailRecM$1(StateT.scala:235)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.runA(StateT.scala:50)
  at fetch.package$Fetch$FetchRunnerA.apply(fetch.scala:242)
  at fetch.syntax$FetchSyntax$.runA$extension0(syntax.scala:48)
  ... 984 elided
Caused by: java.lang.Exception: Something went terribly wrong
  ... 952 more
</code></pre>

<h3 id="join">join</h3>

<p>We can compose two independent fetches with <code>fetch1.join(fetch2)</code>.</p>

<pre><code class="language-scala">val fetchJoined: Fetch[(Post, User)] = getPost(1).join(getUser(2))
</code></pre>

<p>If the fetches are to the same data source they will be batched; if they aren’t, they will be evaluated at the same time.</p>

<pre><code class="language-scala">fetchJoined.runA[Id]
// ~~&gt; [44] One Post 1
// &lt;~~ [44] One Post 1
// ~~&gt; [44] One User 2
// &lt;~~ [44] One User 2
// res40: cats.Id[(Post, User)] = (Post(1,2,An article),User(2,@two))
</code></pre>

<h3 id="runa">runA</h3>

<p>Run directly any fetch with <code>fetch1.runA</code>.</p>

<pre><code class="language-scala">getPost(1).runA[Id]
// ~~&gt; [44] One Post 1
// &lt;~~ [44] One Post 1
// res41: cats.Id[Post] = Post(1,2,An article)
</code></pre>

<h3 id="rune">runE</h3>

<p>Run a fetch an get it’s runtime environment <code>fetch1.runE</code>.</p>

<pre><code class="language-scala">getPost(1).runE[Id]
// ~~&gt; [44] One Post 1
// &lt;~~ [44] One Post 1
// res42: cats.Id[fetch.FetchEnv] = FetchEnv(InMemoryCache(Map((Post,1) -&gt; Post(1,2,An article))),Queue(Round(InMemoryCache(Map()),FetchOne(1,Post),Post(1,2,An article),24924104336412,24924206197806)))
</code></pre>

<h3 id="runf">runF</h3>

<p>Run a fetch obtaining the environment and final value <code>fetch1.runF</code>.</p>

<pre><code class="language-scala">getPost(1).runF[Id]
// ~~&gt; [44] One Post 1
// &lt;~~ [44] One Post 1
// res43: cats.Id[(fetch.FetchEnv, Post)] = (FetchEnv(InMemoryCache(Map((Post,1) -&gt; Post(1,2,An article))),Queue(Round(InMemoryCache(Map()),FetchOne(1,Post),Post(1,2,An article),24924408759284,24924510633918))),Post(1,2,An article))
</code></pre>

<h2 id="companion-object">Companion object</h2>

<p>We’ve been using Cats’ syntax and <code>fetch.syntax</code> throughout the examples since it’s more concise and general than the
methods in the <code>Fetch</code> companion object. However, you can use the methods in the companion object
directly.</p>

<p>Note that using cats syntax gives you a plethora of combinators, much richer that what the companion object provides.</p>

<h3 id="pure-1">pure</h3>

<p>Plain values can be lifted to the Fetch monad with <code>Fetch#pure</code>:</p>

<pre><code class="language-scala">val fetchPure: Fetch[Int] = Fetch.pure(42)
</code></pre>

<p>Executing a pure fetch doesn’t query any data source, as expected.</p>

<pre><code class="language-scala">Fetch.run[Id](fetchPure)
// res44: cats.Id[Int] = 42
</code></pre>

<h3 id="error-1">error</h3>

<p>Errors can also be lifted to the Fetch monad via <code>Fetch#error</code>.</p>

<pre><code class="language-scala">val fetchFail: Fetch[Int] = Fetch.error(new Exception("Something went terribly wrong"))
</code></pre>

<p>Note that interpreting an errorful fetch to <code>Id</code> will throw the exception.</p>

<pre><code class="language-scala">scala&gt; Fetch.run[Id](fetchFail)
fetch.UnhandledException: java.lang.Exception: Something went terribly wrong
  at fetch.FetchInterpreters$$anon$1.$anonfun$apply$1(interpreters.scala:65)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.$anonfun$transformF$1(StateT.scala:81)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateTMonad.$anonfun$tailRecM$2(StateT.scala:236)
  at cats.package$$anon$1.tailRecM(package.scala:36)
  at fetch.unsafe.implicits$$anon$2.tailRecM(unsafeImplicits.scala:106)
  at cats.data.StateTMonad.$anonfun$tailRecM$1(StateT.scala:235)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.$anonfun$transformF$1(StateT.scala:81)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateTMonad.$anonfun$tailRecM$2(StateT.scala:236)
  at cats.package$$anon$1.tailRecM(package.scala:36)
  at fetch.unsafe.implicits$$anon$2.tailRecM(unsafeImplicits.scala:106)
  at cats.data.StateTMonad.$anonfun$tailRecM$1(StateT.scala:235)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.$anonfun$transformF$1(StateT.scala:81)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateTMonad.$anonfun$tailRecM$2(StateT.scala:236)
  at cats.package$$anon$1.tailRecM(package.scala:36)
  at fetch.unsafe.implicits$$anon$2.tailRecM(unsafeImplicits.scala:106)
  at cats.data.StateTMonad.$anonfun$tailRecM$1(StateT.scala:235)
  at cats.data.StateT.$anonfun$run$1(StateT.scala:38)
  at fetch.unsafe.implicits$$anon$2.flatMap(unsafeImplicits.scala:122)
  at cats.data.StateT.run(StateT.scala:38)
  at cats.data.StateT.runA(StateT.scala:50)
  at fetch.package$Fetch$FetchRunnerA.apply(fetch.scala:242)
  ... 985 elided
Caused by: java.lang.Exception: Something went terribly wrong
</code></pre>

<h3 id="join-1">join</h3>

<p>We can compose two independent fetches with <code>Fetch#join</code>.</p>

<pre><code class="language-scala">val fetchJoined: Fetch[(Post, User)] = Fetch.join(getPost(1), getUser(2))
</code></pre>

<p>If the fetches are to the same data source they will be batched; if they aren’t, they will be evaluated at the same time.</p>

<pre><code class="language-scala">Fetch.run[Id](fetchJoined)
// ~~&gt; [44] One Post 1
// &lt;~~ [44] One Post 1
// ~~&gt; [44] One User 2
// &lt;~~ [44] One User 2
// res46: cats.Id[(Post, User)] = (Post(1,2,An article),User(2,@two))
</code></pre>

<h3 id="sequence-1">sequence</h3>

<p>The <code>Fetch#sequence</code> combinator turns a <code>List[Fetch[A]]</code> into a <code>Fetch[List[A]]</code>, running all the fetches concurrently
and batching when possible.</p>

<pre><code class="language-scala">val fetchSequence: Fetch[List[User]] = Fetch.sequence(List(getUser(1), getUser(2), getUser(3)))
</code></pre>

<p>Note that <code>Fetch#sequence</code> is not as general as the <code>sequence</code> method from <code>Traverse</code>, but performs the same optimizations.</p>

<pre><code class="language-scala">Fetch.run[Id](fetchSequence)
// ~~&gt; [44] Many Users NonEmptyList(1, 2, 3)
// &lt;~~ [44] Many Users NonEmptyList(1, 2, 3)
// res47: cats.Id[List[User]] = List(User(1,@one), User(2,@two), User(3,@three))
</code></pre>

<h3 id="traverse-1">traverse</h3>

<p>The <code>Fetch#traverse</code> combinator is a combination of <code>map</code> and <code>sequence</code>.</p>

<pre><code class="language-scala">val fetchTraverse: Fetch[List[User]] = Fetch.traverse(List(1, 2, 3))(getUser)
</code></pre>

<p>Note that <code>Fetch#traverse</code> is not as general as the <code>traverse</code> method from <code>Traverse</code>, but performs the same optimizations.</p>

<pre><code class="language-scala">Fetch.run[Id](fetchTraverse)
// ~~&gt; [44] Many Users NonEmptyList(1, 2, 3)
// &lt;~~ [44] Many Users NonEmptyList(1, 2, 3)
// res48: cats.Id[List[User]] = List(User(1,@one), User(2,@two), User(3,@three))
</code></pre>

<h2 id="cats">cats</h2>

<p>Fetch is built using Cats’ Free monad construction and thus works out of the box with
cats syntax. Using Cats’ syntax, we can make fetch declarations more concise, without
the need to use the combinators in the <code>Fetch</code> companion object.</p>

<p>Fetch provides its own instance of <code>Applicative[Fetch]</code>. Whenever we use applicative
operations on more than one <code>Fetch</code>, we know that the fetches are independent meaning
we can perform optimizations such as batching and concurrent requests.</p>

<p>If we were to use the default <code>Applicative[Fetch]</code> operations, which are implemented in terms of <code>flatMap</code>,
we wouldn’t have information about the independency of multiple fetches.</p>

<h3 id="applicative">Applicative</h3>

<p>The <code>|@|</code> operator allows us to combine multiple independent fetches, even when they
are from different types, and apply a pure function to their results. We can use it
as a more powerful alternative to the <code>product</code> method or <code>Fetch#join</code>:</p>

<pre><code class="language-scala">import cats.syntax.cartesian._

val fetchThree: Fetch[(Post, User, Post)] = (getPost(1) |@| getUser(2) |@| getPost(2)).tupled
</code></pre>

<p>Notice how the queries to posts are batched.</p>

<pre><code class="language-scala">fetchThree.runA[Id]
// ~~&gt; [44] Many Posts NonEmptyList(1, 2)
// &lt;~~ [44] Many Posts NonEmptyList(1, 2)
// ~~&gt; [44] One User 2
// &lt;~~ [44] One User 2
// res50: cats.Id[(Post, User, Post)] = (Post(1,2,An article),User(2,@two),Post(2,3,Another article))
</code></pre>

<p>More interestingly, we can use it to apply a pure function to the results of various
fetches.</p>

<pre><code class="language-scala">val fetchFriends: Fetch[String] = (getUser(1) |@| getUser(2)).map({ (one, other) =&gt;
  s"${one.username} is friends with ${other.username}"
})
// fetchFriends: fetch.Fetch[String] = Free(...)

fetchFriends.runA[Id]
// ~~&gt; [44] Many Users NonEmptyList(1, 2)
// &lt;~~ [44] Many Users NonEmptyList(1, 2)
// res51: cats.Id[String] = @one is friends with @two
</code></pre>

<p>The above example is equivalent to the following using the <code>Fetch#join</code> method:</p>

<pre><code class="language-scala">val fetchFriends: Fetch[String] = Fetch.join(getUser(1), getUser(2)).map({ case (one, other) =&gt;
  s"${one.username} is friends with ${other.username}"
})
// fetchFriends: fetch.Fetch[String] = Free(...)

fetchFriends.runA[Id]
// ~~&gt; [44] Many Users NonEmptyList(1, 2)
// &lt;~~ [44] Many Users NonEmptyList(1, 2)
// res52: cats.Id[String] = @one is friends with @two
</code></pre>

<h1 id="concurrency-monads">Concurrency monads</h1>

<p>Fetch lets you choose the concurrency monad you want for running fetches, supporting the Scala and Scala.js
standard library concurrency primitives. However not everyone is using <code>Future</code> and Fetch acknowledges it,
providing support for the most widespread concurrency monads and making it easy for users to run a fetch to a
custom type.</p>

<p>For supporting running a fetch to a monad <code>M[_]</code> an instance of <code>FetchMonadError[M]</code> must be available.</p>

<p>We’ll use the following fetches for the examples. They show how we can combine independent fetches both for
batching and exploiting the concurrency of independent data.</p>

<pre><code class="language-scala">val postsByAuthor: Fetch[List[Post]] = for {
  posts &lt;- List(1, 2).traverse(getPost)
  authors &lt;- posts.traverse(getAuthor)
  ordered = (posts zip authors).sortBy({ case (_, author) =&gt; author.username }).map(_._1)
} yield ordered

val postTopics: Fetch[Map[PostTopic, Int]] = for {
  posts &lt;- List(2, 3).traverse(getPost)
  topics &lt;- posts.traverse(getPostTopic)
  countByTopic = (posts zip topics).groupBy(_._2).mapValues(_.size)
} yield countByTopic

val homePage = (postsByAuthor |@| postTopics).tupled
</code></pre>

<h2 id="future">Future</h2>

<p>You can run a fetch into a <code>Future</code> simply by importing <code>fetch.implicits</code>. It
contains an instance of <code>FetchMonadError[Future]</code> given that you provide an implicit <code>ExecutionContext</code>.</p>

<p>For the sake of the examples we’ll use the global <code>ExecutionContext</code>.</p>

<pre><code class="language-scala">Await.result(Fetch.run[Future](homePage),  Duration.Inf)
// ~~&gt; [47] Many Posts NonEmptyList(1, 2, 3)
// &lt;~~ [47] Many Posts NonEmptyList(1, 2, 3)
// ~~&gt; [49] Many Users NonEmptyList(2, 3)
// ~~&gt; [47] Many Post Topics NonEmptyList(Post(2,3,Another article), Post(3,4,Yet another article))
// &lt;~~ [49] Many Users NonEmptyList(2, 3)
// &lt;~~ [47] Many Post Topics NonEmptyList(Post(2,3,Another article), Post(3,4,Yet another article))
// res55: (List[Post], Map[PostTopic,Int]) = (List(Post(2,3,Another article), Post(1,2,An article)),Map(monad -&gt; 1, applicative -&gt; 1))
</code></pre>

<h2 id="monix-task">Monix Task</h2>

<p>The <a href="https://monix.io/">Monix</a> library provides an abstraction for lazy, asynchronous computations with its <a href="https://monix.io/docs/2x/eval/task.html">Task</a> type.</p>

<p>For using <code>Task</code> as the target concurrency monad of a fetch, add the following dependency to your build file:</p>

<pre><code class="language-scala">"com.fortysevendeg" %% "fetch-monix" % "0.4.1-SNAPSHOT"
</code></pre>

<p>And do some standard imports, we’ll need an Scheduler for running our tasks as well as the instance of <code>FetchMonadError[Task]</code> that <code>fetch-monix</code> provides:</p>

<pre><code class="language-scala">import monix.eval.Task
import monix.execution.Scheduler

import fetch.monixTask.implicits._
</code></pre>

<p>Note that running a fetch to a <code>Task</code> doesn’t trigger execution. We can interpret a task to a <code>Future</code> with the <code>Task#runAsync</code> method. We’ll use the global scheduler for now.</p>

<pre><code class="language-scala">val scheduler = Scheduler.Implicits.global
// scheduler: monix.execution.Scheduler = monix.execution.schedulers.AsyncScheduler@78fd7ed3

val task = Fetch.run[Task](homePage)
// task: monix.eval.Task[(List[Post], Map[PostTopic,Int])] = BindSuspend(monix.eval.Task$$Lambda$2026/1947039830@640af65d,monix.eval.Task$$Lambda$2027/1190469298@31db7274)

Await.result(task.runAsync(scheduler), Duration.Inf)
// ~~&gt; [51] Many Posts NonEmptyList(1, 2, 3)
// &lt;~~ [51] Many Posts NonEmptyList(1, 2, 3)
// ~~&gt; [50] Many Post Topics NonEmptyList(Post(2,3,Another article), Post(3,4,Yet another article))
// ~~&gt; [47] Many Users NonEmptyList(2, 3)
// &lt;~~ [50] Many Post Topics NonEmptyList(Post(2,3,Another article), Post(3,4,Yet another article))
// &lt;~~ [47] Many Users NonEmptyList(2, 3)
// res57: (List[Post], Map[PostTopic,Int]) = (List(Post(2,3,Another article), Post(1,2,An article)),Map(monad -&gt; 1, applicative -&gt; 1))
</code></pre>

<h3 id="jvm">JVM</h3>

<p>In the JVM, you may want to choose a <a href="https://monix.io/docs/2x/execution/scheduler.html#builders-on-the-jvm">scheduler tuned for IO workloads</a> to interpret fetches.</p>

<pre><code class="language-scala">val ioSched = Scheduler.io(name="io-scheduler")
// ioSched: monix.execution.Scheduler = monix.execution.schedulers.AsyncScheduler@295e9964

Await.result(task.runAsync(ioSched), Duration.Inf)
// ~~&gt; [53] Many Posts NonEmptyList(1, 2, 3)
// &lt;~~ [53] Many Posts NonEmptyList(1, 2, 3)
// ~~&gt; [55] Many Users NonEmptyList(2, 3)
// ~~&gt; [56] Many Post Topics NonEmptyList(Post(2,3,Another article), Post(3,4,Yet another article))
// &lt;~~ [55] Many Users NonEmptyList(2, 3)
// &lt;~~ [56] Many Post Topics NonEmptyList(Post(2,3,Another article), Post(3,4,Yet another article))
// res58: (List[Post], Map[PostTopic,Int]) = (List(Post(2,3,Another article), Post(1,2,An article)),Map(monad -&gt; 1, applicative -&gt; 1))
</code></pre>

<h2 id="custom-types">Custom types</h2>

<p>If you want to run a fetch to a custom type <code>M[_]</code>, you need to implement the <code>FetchMonadError[M]</code> typeclass. <code>FetchMonadError[M]</code> is simply a <code>MonadError[M, FetchException]</code> from cats augmented
with a method for running a <code>Query[A]</code> in the context of the monad <code>M[A]</code>.</p>

<p>For ilustrating integration with an asynchronous concurrency monad we’ll use the implementation of Monix Task.</p>

<h3 id="running-queries">Running queries</h3>

<p>First of all, we need to run queries in our target type. As we have learned, queries can be synchronous (simply wrapping an <code>Eval</code> from Cats) or asynchronous. Since we’ll need to lift
<code>Eval[A]</code> values to <code>Task[A]</code>, let’s write a function for doing so first. Note that Monix’s <code>Task</code> supports the same evaluation strategies of <code>Eval</code> in Cats, so the conversion is very
direct:</p>

<pre><code class="language-scala">import cats.{Eval, Now, Later, Always}
import monix.eval.Task

def evalToTask[A](e: Eval[A]): Task[A] = e match {
  case Now(x) =&gt; Task.now(x)
  case l: Later[A]  =&gt; Task.evalOnce(l.value)
  case a: Always[A] =&gt; Task.eval(a.value)
  case other =&gt; Task.evalOnce(other.value)
}
</code></pre>

<p>Now that we can run synchronous queries to <code>Task</code>, we’ll use <code>Task#create</code> for running asynchronous computations. Queries also have a third option: <code>Ap</code>, which delegates the applicative combination of independent queries to the target monad.</p>

<pre><code class="language-scala">import monix.execution.Cancelable
import scala.concurrent.duration._

def queryToTask[A](q: Query[A]): Task[A] = q match {
  case Sync(e) =&gt; evalToTask(e)
  case Async(action, timeout) =&gt; {
    val task: Task[A] = Task.create((scheduler, callback) =&gt; {
	  scheduler.execute(new Runnable {
        def run() = action(callback.onSuccess, callback.onError)
      })

      Cancelable.empty
    })

    timeout match {
      case finite: FiniteDuration =&gt; task.timeout(finite)
      case _                      =&gt; task
    }
  }
  case Ap(qf, qx) =&gt; Task.zip2(queryToTask(qf), queryToTask(qx)).map({ case (f, x) =&gt; f(x) })	
}
</code></pre>

<p>The asynchronous action was built using <code>Task#create</code>; it receives the used scheduler and a callback, runs
the async action in the scheduler passing the success and error versions of the callback and returns an empty
cancelable (it can not be canceled); if we encounter a finite duration timeout, we set it on the task.</p>

<p>The applicative action used <code>Task#zip2</code> to combine two tasks and apply the function contained in one of them
to the other. We used <code>Task#zip2</code> for expressing the independence between the two tasks, which can potentially
be evaluated in parallel.</p>

<h3 id="writing-the-fetchmonaderror-instance">Writing the FetchMonadError instance</h3>

<p>Now we’re ready for implementing the FetchMonadError instance for <code>Task</code>, we need to define it as an implicit. 
Note that Cats’ typeclass hierarchy is expressed with inheritance and methods from weaker typeclasses like <code>Functor</code> or <code>Applicative</code> in more powerful typeclasses like <code>Monad</code> are implemented in terms of the operations of the latter. In practice, this means that if you just implement <code>pure</code> and <code>flatMap</code> the rest of the combinators like <code>map</code> are going to be implemented in terms of them. Because of this we’ll override <code>map</code> for not using <code>flatMap</code> and <code>product</code> for expressing the independence of two computations.</p>

<p>We make use of the <code>FromMonadError</code> class below, making it easer to implement <code>FetchMonadError[Task]</code> given a <code>MonadError[Task, Throwable]</code> which we can get from the <em>monix-cats</em> projects.</p>

<pre><code class="language-scala">import monix.cats._

implicit val taskFetchMonadError: FetchMonadError[Task] =
  new FetchMonadError.FromMonadError[Task] {
    override def runQuery[A](q: Query[A]): Task[A] = queryToTask[A](q)

    override def map[A, B](fa: Task[A])(f: A =&gt; B): Task[B] =
      fa.map(f)

    override def product[A, B](fa: Task[A], fb: Task[B]): Task[(A, B)] =
      Task.zip2(Task.fork(fa), Task.fork(fb))
  }
</code></pre>

<p>We can now import the above implicit and run a fetch to our custom type, let’s give it a go:</p>

<pre><code class="language-scala">val task = Fetch.run(homePage)(taskFetchMonadError)
// task: monix.eval.Task[(List[Post], Map[PostTopic,Int])] = BindSuspend(monix.eval.Task$$Lambda$2026/1947039830@832bb50,monix.eval.Task$$Lambda$2027/1190469298@239874df)

Await.result(task.runAsync(scheduler), Duration.Inf)
// ~~&gt; [50] Many Posts NonEmptyList(1, 2, 3)
// &lt;~~ [50] Many Posts NonEmptyList(1, 2, 3)
// ~~&gt; [50] Many Post Topics NonEmptyList(Post(2,3,Another article), Post(3,4,Yet another article))
// ~~&gt; [51] Many Users NonEmptyList(2, 3)
// &lt;~~ [50] Many Post Topics NonEmptyList(Post(2,3,Another article), Post(3,4,Yet another article))
// &lt;~~ [51] Many Users NonEmptyList(2, 3)
// res62: (List[Post], Map[PostTopic,Int]) = (List(Post(2,3,Another article), Post(1,2,An article)),Map(monad -&gt; 1, applicative -&gt; 1))
</code></pre>

<h1 id="debugging">Debugging</h1>

<p>We have introduced the handy <code>fetch.debug.describe</code> function for debugging errors, but it can do more than that. It can also give you a detailed description of
a fetch execution given an environment.</p>

<p>Add the following line to your dependencies for including Fetch’s debugging facilities:</p>

<pre><code class="language-scala">"com.fortysevendeg" %% "fetch-debug" % "0.4.1-SNAPSHOT"
</code></pre>

<h2 id="fetch-execution">Fetch execution</h2>

<p>We are going to create an interesting fetch that applies all the optimizations available (caching, batching and concurrent request) for ilustrating how we can
visualize fetch executions using the environment.</p>

<pre><code class="language-scala">val batched: Fetch[List[User]] = Fetch.multiple(1, 2)
val cached: Fetch[User] = getUser(2)
val concurrent: Fetch[(List[User], List[Post])] = (List(1, 2, 3).traverse(getUser) |@| List(1, 2, 3).traverse(getPost)).tupled

val interestingFetch = for {
  users &lt;- batched
  anotherUser &lt;- cached
  _ &lt;- concurrent
} yield "done"
</code></pre>

<p>Now that we have the fetch let’s run it, get the environment and visualize its execution using the <code>describe</code> function:</p>

<pre><code class="language-scala">import fetch.debug.describe
// import fetch.debug.describe

val env = interestingFetch.runE[Id]
// ~~&gt; [44] Many Users NonEmptyList(1, 2)
// &lt;~~ [44] Many Users NonEmptyList(1, 2)
// ~~&gt; [44] One User 3
// &lt;~~ [44] One User 3
// ~~&gt; [44] Many Posts NonEmptyList(1, 2, 3)
// &lt;~~ [44] Many Posts NonEmptyList(1, 2, 3)
// env: cats.Id[fetch.FetchEnv] = FetchEnv(InMemoryCache(Map((Post,2) -&gt; Post(2,3,Another article), (User,2) -&gt; User(2,@two), (User,3) -&gt; User(3,@three), (User,1) -&gt; User(1,@one), (Post,3) -&gt; Post(3,4,Yet another article), (Post,1) -&gt; Post(1,2,An article))),Queue(Round(InMemoryCache(Map()),FetchMany(NonEmptyList(1, 2),User),List(User(1,@one), User(2,@two)),24935781324662,24935890902648), Round(InMemoryCache(Map((User,1) -&gt; User(1,@one), (User,2) -&gt; User(2,@two))),Concurrent(NonEmptyList(FetchOne(3,User), FetchMany(NonEmptyList(1, 2, 3),Post))),NonEmptyList(Map(3 -&gt; User(3,@three)), Map(1 -&gt; Post(1,2,An article), 2 -&gt; Post(2,3,Another article), 3 -&gt; Post(3,4,Yet another article))),24935891971151,24936098596200)))

println(describe(env))
// Fetch execution took 0.317272 seconds
// 
//   [Fetch many] From `User` with ids List(1, 2) took 0.000110 seconds
//   [Concurrent] took 0.000207 seconds
//     [Fetch one] From `User` with id 3
//     [Fetch many] From `Post` with ids List(1, 2, 3)
</code></pre>

<p>Let’s break down the output from <code>describe</code>:</p>

<ul>
  <li>The first line shows the total time that took to run the fetch</li>
  <li>The nested lines represent the different rounds of execution</li>
  <li>“Fetch one” rounds are executed for getting an identity from one data source</li>
  <li>“Fetch many” rounds are executed for getting a batch of identities from one data source</li>
  <li>“Concurrent” rounds are multiple “one” or “many” rounds for different data sources executed concurrently</li>
</ul>

<h1 id="resources">Resources</h1>

<ul>
  <li><a href="https://github.com/47deg/fetch">Code</a> on GitHub.</li>
  <li><a href="http://47deg.github.io/fetch/">Documentation site</a></li>
  <li><a href="https://www.youtube.com/watch?v=45fcKYFb0EU">Fetch: Simple &amp; Efficient data access</a> talk at <a href="http://typelevel.org/event/2016-05-summit-oslo/">Typelevel Summit in Oslo</a></li>
</ul>

<h1 id="acknowledgements">Acknowledgements</h1>

<p>Fetch stands on the shoulders of giants:</p>

<ul>
  <li><a href="https://github.com/facebook/haxl">Haxl</a> is Facebook’s implementation (Haskell) of the <a href="http://community.haskell.org/~simonmar/papers/haxl-icfp14.pdf">original paper Fetch is based on</a>.</li>
  <li><a href="http://getclump.io">Clump</a> has inspired the signature of the <code>DataSource#fetch*</code> methods.</li>
  <li><a href="https://engineering.twitter.com/university/videos/introducing-stitch">Stitch</a> is an in-house Twitter library that is not open source but has inspired Fetch’s high-level API.</li>
  <li><a href="http://typelevel.org/cats/">Cats</a>, a library for functional programming in Scala.</li>
  <li><a href="https://monix.io">Monix</a> high-performance and multiplatform (Scala / Scala.js) asynchronous programming library.</li>
</ul>

</section></div></div></div></div><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.3.7/js/bootstrap.min.js"></script><script src="/fetch/highlight/highlight.pack.js"></script><script>hljs.configure({
languages:['scala','java','bash']
});
hljs.initHighlighting();
             </script><script src="/fetch/js/automenu.js"></script><script src="/fetch/js/main.js"></script></body></html>